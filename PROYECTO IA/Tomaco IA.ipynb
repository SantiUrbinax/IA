{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2801e6f7-6daa-4844-82ab-0a0e87c7569a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/sujaykapadnis/tomato-maturity-detection-and-quality-grading?dataset_version_number=1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 5.08G/5.08G [11:15<00:00, 8.08MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\vasqu\\.cache\\kagglehub\\datasets\\sujaykapadnis\\tomato-maturity-detection-and-quality-grading\\versions\\1\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"sujaykapadnis/tomato-maturity-detection-and-quality-grading\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "454f19bd-03b0-4570-989e-c321a5e717d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\vasqu\\.cache\\kagglehub\\datasets\\sujaykapadnis\\tomato-maturity-detection-and-quality-grading\\versions\\1\n"
     ]
    }
   ],
   "source": [
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "10bff03d-bbd0-4699-9120-a7d1787b62ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4000 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n",
      "Found 6389 images belonging to 2 classes.\n",
      "Found 1597 images belonging to 2 classes.\n",
      "Epoch 1/3\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m559s\u001b[0m 4s/step - accuracy: 0.7795 - loss: 0.4424 - val_accuracy: 0.8360 - val_loss: 0.5206\n",
      "Epoch 2/3\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m558s\u001b[0m 4s/step - accuracy: 0.9700 - loss: 0.1145 - val_accuracy: 0.9700 - val_loss: 0.0765\n",
      "Epoch 3/3\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m520s\u001b[0m 4s/step - accuracy: 0.9722 - loss: 0.0786 - val_accuracy: 0.9830 - val_loss: 0.0530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m899s\u001b[0m 4s/step - accuracy: 0.5722 - loss: 0.6983 - val_accuracy: 0.7683 - val_loss: 0.4632\n",
      "Epoch 2/3\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m917s\u001b[0m 5s/step - accuracy: 0.7524 - loss: 0.4949 - val_accuracy: 0.8892 - val_loss: 0.3014\n",
      "Epoch 3/3\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m916s\u001b[0m 5s/step - accuracy: 0.8775 - loss: 0.3159 - val_accuracy: 0.9436 - val_loss: 0.1846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# --- Configuración ---\n",
    "IMAGE_SIZE = (128, 128)\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 3\n",
    "BASE_DIR   = r\"C:\\Users\\vasqu\\.cache\\kagglehub\\datasets\\sujaykapadnis\\tomato-maturity-detection-and-quality-grading\\versions\\1\\Tomato Maturity Detection and Quality Grading Dataset\"\n",
    "\n",
    "# Rutas a los dos sub‑datasets\n",
    "MATURITY_DIR = os.path.join(BASE_DIR, \"Tomato Maturity Detection Dataset\",\"Tomato Maturity Detection Dataset\", \"Original Dataset\")\n",
    "QUALITY_DIR  = os.path.join(BASE_DIR, \"Tomato Quality Grading Dataset\", \"Tomato Quality Grading Dataset\", \"Original Dataset\")\n",
    "\n",
    "# Creamos un generador con split para train/val\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.2,\n",
    "    horizontal_flip=True,\n",
    "    zoom_range=0.2\n",
    ")\n",
    "\n",
    "# 1) Generators para MADUREZ (Immature vs Mature)\n",
    "train_mat = datagen.flow_from_directory(\n",
    "    MATURITY_DIR,\n",
    "    target_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    classes=['Immature','Mature'],\n",
    "    class_mode='binary',\n",
    "    subset='training'\n",
    ")\n",
    "val_mat = datagen.flow_from_directory(\n",
    "    MATURITY_DIR,\n",
    "    target_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    classes=['Immature','Mature'],\n",
    "    class_mode='binary',\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "# 2) Generators para CALIDAD (Rotten vs Fresh)\n",
    "train_qual = datagen.flow_from_directory(\n",
    "    QUALITY_DIR,\n",
    "    target_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    classes=['Rotten','Fresh'],\n",
    "    class_mode='binary',\n",
    "    subset='training'\n",
    ")\n",
    "val_qual = datagen.flow_from_directory(\n",
    "    QUALITY_DIR,\n",
    "    target_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    classes=['Rotten','Fresh'],\n",
    "    class_mode='binary',\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "# Función para crear la misma arquitectura\n",
    "def build_binary_model(input_shape=(*IMAGE_SIZE, 3)):\n",
    "    model = Sequential([\n",
    "        Conv2D(32, (3,3), activation='relu', input_shape=input_shape),\n",
    "        MaxPooling2D(2,2),\n",
    "        Conv2D(64, (3,3), activation='relu'),\n",
    "        MaxPooling2D(2,2),\n",
    "        Conv2D(128, (3,3), activation='relu'),\n",
    "        MaxPooling2D(2,2),\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# — Entrenar modelo de MADUREZ —\n",
    "model_mat = build_binary_model()\n",
    "model_mat.fit(\n",
    "    train_mat,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=val_mat\n",
    ")\n",
    "model_mat.save('tomato_maturity_model.h5')\n",
    "\n",
    "\n",
    "# — Entrenar modelo de CALIDAD —\n",
    "model_qual = build_binary_model()\n",
    "model_qual.fit(\n",
    "    train_qual,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=val_qual\n",
    ")\n",
    "model_qual.save('tomato_quality_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f4d98b98-4cea-4504-a08a-80395481c623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hola\n"
     ]
    }
   ],
   "source": [
    "print(\"hola\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79d6d93c-6a03-4181-b948-02ed7801af35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step\n",
      "🧐 Resultado para \"C:\\Users\\urbin\\PROYECTO IA\\prueba1.jpg\":\n",
      "  • Madurez: Mature\n",
      "  • Calidad: Rotten\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# --- Configuración ---\n",
    "IMAGE_SIZE = (128, 128)\n",
    "THRESHOLD = 0.5\n",
    "\n",
    "# Ajusta aquí la ruta absoluta a tu escritorio y al nombre exacto de tu archivo:\n",
    "IMG_PATH = r\"C:\\Users\\urbin\\PROYECTO IA\\prueba1.jpg\"   # o .png, .jpeg, etc\n",
    "# Rutas a los modelos que ya entrenaste y guardaste\n",
    "MATURITY_MODEL_PATH = 'tomato_maturity_model.h5'\n",
    "QUALITY_MODEL_PATH  = 'tomato_quality_model.h5'\n",
    "\n",
    "# Mapas de etiquetas\n",
    "MATURITY_LABELS = {0: 'Immature', 1: 'Mature'}\n",
    "QUALITY_LABELS  = {0: 'Rotten',   1: 'Fresh'}\n",
    "\n",
    "# --- Funciones de ayuda ---\n",
    "def preprocess_image(img_path, target_size=IMAGE_SIZE):\n",
    "    img = load_img(img_path, target_size=target_size)\n",
    "    x   = img_to_array(img) / 255.0\n",
    "    return np.expand_dims(x, axis=0)\n",
    "\n",
    "def predict_tomato(img_path, maturity_model, quality_model):\n",
    "    x = preprocess_image(img_path)\n",
    "    m_pred = maturity_model.predict(x)[0][0]\n",
    "    q_pred = quality_model.predict(x)[0][0]\n",
    "    m_cls  = 1 if m_pred > THRESHOLD else 0\n",
    "    q_cls  = 1 if q_pred > THRESHOLD else 0\n",
    "    return MATURITY_LABELS[m_cls], QUALITY_LABELS[q_cls]\n",
    "\n",
    "# --- Carga modelos ---\n",
    "if not os.path.exists(MATURITY_MODEL_PATH) or not os.path.exists(QUALITY_MODEL_PATH):\n",
    "    raise FileNotFoundError(\"Asegúrate de tener ambos archivos .h5 en el mismo directorio que este script.\")\n",
    "\n",
    "maturity_model = load_model(MATURITY_MODEL_PATH)\n",
    "quality_model  = load_model(QUALITY_MODEL_PATH)\n",
    "\n",
    "# --- Predicción directa ---\n",
    "maturity, quality = predict_tomato(IMG_PATH, maturity_model, quality_model)\n",
    "print(f'🧐 Resultado para \"{IMG_PATH}\":')\n",
    "print(f'  • Madurez: {maturity}')\n",
    "print(f'  • Calidad: {quality}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1181b389-43d8-4afb-9312-07776f2e4a0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
